---
layout: default
---

# Workshop Description

Welcome to the world of Big Data! Every day, more than 370 millions of TB of data is generated in the world. Extracting value out of it requires us to understand all the different ways it can be stored and processed. This workshop is designed to help everyone, from curious learners to seasoned professionals, understand Big Data and the profound implications it has across industries.

Together, we will discover the complexities of Big Data, dive into its ecosystem, and get hands-on experience with tools like Apache Spark and its Python library. Our objective is to give you a solid overview of the Big Data landscape and delve into the use of one of its most important tools - Spark. We will also teach you how the latest AI tools can be used to improve your efficiency in processing data.

This workshop isn't just about learning—it's about truly experiencing the world of Big Data in a modern way. Join us for an enlightening journey!

**Want to make sure this is the right workshop for you? Check out the workshop’s prerequisites below.**

This workshop will assume basic knowledge of Python for the few technical use-cases we will cover. Ability to use notebooks / Google Colab would help you get to work faster, but we will cover that briefly if you have never used it. You do not need to install Python or any other software before the workshop. We will provide more detailed instructions prior to the start to ensure that you are set up and ready to learn.

Our goal is to create an inclusive and supportive learning environment, and we want all students to succeed. However, to set you up for success, we also want to clearly communicate the necessary level of prior programming familiarity. If you are unsure whether you have the required background, please feel free to reach out for guidance.

To join the workshop, you'll need a device with a recent web browser and two-way audio and video access to Zoom. This could be a laptop or desktop computer running any operating system, such as Windows, Mac, or Linux. Participative activities benefit from a larger screen, so joining via a smartphone or tablet may not provide the best learning experience.

## About the Instructors

![Axel](/assets/img/profile_axel.jpg){:style="max-width:30%;"}
[LinkedIn](https://www.linkedin.com/in/axel-peytavin/)

Axel Peytavin earned his M.S. from ICME in June 2023, and is currently pursuing research on Twitter data with Professor Johan Ugander and Professor Martin Saveski in Stanford’s department of Management Science & Engineering. He is also a volunteer for The Ocean Cleanup, for which we worked as a computational modeler prior to coming to Stanford, and a co-founder of the GetAlong project to bring better discussions on information on the internet.

![Julia](/assets/img/profile_julia.jpg){:style="max-width:30%;"}
[LinkedIn](https://www.linkedin.com/in/anna-julia-storch-517142144/)

Anna-Julia Storch recently earned her M.S. in Education Data Science from Stanford, exploring how data science can help us solve educational challenges. She has also been a teaching assistant for Stanford's premier entrepreneurship courses including "The Lean Launchpad" (taught be Steve Blank). Prior to Stanford, she has worked in a variety of roles including as a digital consultant for a big data project at McKinsey, in VC-backed technology startups and as a business line head for a multinational HR company.

# Workshop Materials

## Pre-workshop Checklist

TBD

## Schedule

#### July 25 (1:00 - 4 P.M. PST) : Introduction and Data Storage Concepts

1. Introduction to Big Data

- Definition, relevance, the V's, challenges

2. Real-world Applications of Big Data

- Industry and research examples: Netflix, log processing, The Ocean Cleanup
- Activity: Group discussion on students' experiences with Big Data

3. Data Storage Overview

- Explanation of different ways of storing data: Relational, NoSQL, data warehouses, data lakes

4. Hands-on Activities with Data Storage

- Relational Databases: SQLite in Google Colab
- NoSQL Databases: MongoDB in Google Colab
- Data Warehouses and Data Lakes: Exploration of real-world data in cloud platforms

5. Q&A and Wrap Up

#### July 26 (1:00 - 4 P.M. PST) : Big Data Processing and Future Directions

1. Introduction to Apache Spark and Hadoop

- Definition, relevance, use cases, comparison of Spark and Hadoop

2. Hands-on Activities with Data Processing

- Basic Data Processing with PySpark: Reading, writing, and basic data manipulation on a simple CS 246 dataset
- Advanced Data Processing with PySpark: Joining data, working with complex data types

3. Relating to More Standard Data Processing Tools

- PySpark SQL and DataFrame API
- Activity: Exercises with PySpark SQL and DataFrame API

4. The Future of Big Data

- Big Data in the AI era: Using ChatGPT for faster data processing

5. Closing Remarks

- Overview of additional Big Data tools and libraries
- Recommendations for further learning
- Q&A and discussion on students' future Big Data interests

## Additional Resources

We will add here additional resources that we think are useful for you to learn more about Big Data.
